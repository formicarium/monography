\documentclass[twosideprint]{politex}
% ========== Opções ==========
% pnumromarab - Numeração de páginas usando algarismos romanos na parte pré-textual e arábicos na parte textual
% abnttoc - Forçar paginação no sumário conforme ABNT (inclui "p." na frente das páginas)
% normalnum - Numeração contínua de figuras e tabelas 
%	(caso contrário, a numeração é reiniciada a cada capítulo)
% draftprint - Ajusta as margens para impressão de rascunhos
%	(reduz a margem interna)
% twosideprint - Ajusta as margens para impressão frente e verso
% capsec - Forçar letras maiúsculas no título das seções
% espacosimples - Documento usando espaçamento simples
% espacoduplo - Documento usando espaçamento duplo
%	(o padrão é usar espaçamento 1.5)
% times - Tenta usar a fonte Times New Roman para o corpo do texto
% noindentfirst - Não indenta o primeiro parágrafo dos capítulos/seções


% ========== Packages ==========
\usepackage[utf8]{inputenc}
\usepackage{amsmath,amsthm,amsfonts,amssymb}
\usepackage{graphicx,cite,enumerate}

\usepackage[brazil]{babel}
%\usepackage[english]{babel}
%\usepackage{caption}
%\usepackage{subcaption}
% ========== ABNT (requer ABNTeX 2) ==========
%	http://www.ctan.org/tex-archive/macros/latex/contrib/abntex2
\usepackage[num,overcite]{abntex2cite}

% Forçar o abntex2 a usar [ ] nas referências ao invés de ( )
\citebrackets{[}{]}

% ========== Lorem ipsum ==========
\usepackage{blindtext}

\usepackage{array}

\newcommand{\legend}[1]{\begin{center}\def\caption{}\caption{#1}\end{center}}
% \newcommand{\legend}[1]{\begin{center}\def\caption{}\makebox[\textwidth][s]{\caption{#1}} \par\end{center}}

% ========== Opções do documento ==========
% Título
\titulo{Formicarium: Ambiente de desenvolvimento em tempo real para microsserviços}

% Autor
\autor{Leonardo C. S. Iacovini\\
		Luiz G. Santos\\
		Rafael L. D. R. Santos\\
		Rafael R. Correia}

% Orientador / Coorientador
\orientador{Jorge Risco Becerra}
\coorientador{Rafael de França Ferreira}

% Tipo de documento
\tcc{de Computação}
%\dissertacao{Engenharia Elétrica}
%\teseDOC{Engenharia Elétrica}
%\teseLD
%\memorialLD

% Departamento e área de concentração
\departamento{PCS}
\areaConcentracao{Engenharia de Software}

% Local
\local{São Paulo}

% Ano
\data{2018}




\begin{document}
% ========== Capa e folhas de rosto ==========
\capa
% \falsafolhaderosto
\folhaderosto


% ========== Folha de assinaturas (opcional) ==========
%\begin{folhadeaprovacao}
%	\assinatura{Prof.\ X}
%	\assinatura{Prof.\ Y}
%	\assinatura{Prof.\ Z}
%\end{folhadeaprovacao}


% ========== Ficha catalográfica ==========
% Fazer solicitação no site:
%	http://www.poli.usp.br/en/bibliotecas/servicos/catalogacao-na-publicacao.html


% ========== Dedicatória (opcional) ==========
%\dedicatoria{Dedicatória}


% ========== Agradecimentos ==========
\begin{agradecimentos}

Valeu Risco, é nois

\end{agradecimentos}


% ========== Epígrafe (opcional) ==========
%\epigrafe{%
%	\emph{``Epígrafe''}
%	\begin{flushright}
%		-{}- Autor
%	\end{flushright}
%}


% ========== Resumo ==========
\begin{resumo}
	Em uma arquitetura distribuída de microsserviços, é comum enfrentar problemas relacionados à produtividade enquanto o software é desenvolvido. Uma das causas deste problema é a necessidade de se executar diversos microsserviços ao mesmo tempo para iterar, testar e validar algum fluxo de negócio. Estes processos computacionais demandam uma quantidade de recursos (processamento e memória) que nem sempre estão disponíveis na máquina do desenvolvedor.
	
	Um outro problema comum é a dificuldade de se entender e depurar fluxos complexos de negócio que envolvam comunicação entre diversos microsserviços através de diferentes protocolos de troca de mensagens.
	
	Foi neste contexto que surgiu a parceria entre a Poli e o Nubank para o desenvolvimento de um projeto que tentasse mitigar os problemas acima descritos.
	
%%	O Nubank é uma fintech brasileira que conta com mais de 200 engenheiros, trabalhando diariamente em mais de 200 microsserviços para atender os mais de 5 milhões de clientes ativos em seus diversos produtos. A empresa é referência nacional e mundial em tecnologia, devido a sua arquitetura de software moderna, baseada em microsserviços. Porém, as implicações negativas deste modelo já estão se manifestando na empresa há algum tempo, prejudicando a produtividade das equipes.
	
	O projeto foi co-orientado por um dos engenheiros mais prestigiados do Nubank, que está presente na empresa desde praticamente o seu nascimento, sendo responsável por importantes decisões arquiteturais e por ter participado da construção da fundação de toda a tecnologia da empresa.
	
	Através do intenso uso de computação em nuvem, orquestração de Containers Docker, conceitos de Distributed Tracing e técnicas para sincronização de file systems, este projeto visa aumentar a produtividade dos engenheiros do Nubank em suas tarefas de desenvolvimento e manutenção dos microsserviços da empresa.
	
	Para o desenho da solução, foi feito um estudo profundo sobre modelos de PaaS, características de microsserviços de modo geral, bem como seu uso no contexto específico do Nubank. 
	
	O resultado foi a construção de um ambiente de desenvolvimento para arquiteturas de larga escala baseada em microsserviços, chamado de Formicarium. O projeto foi implantado em um squad do Nubank nos últimos meses de desenvolvimento do trabalho para que feedbacks pudessem ser colhidos e para que fossem feitos os ajustes necessários.
	
	Com base nos resultados, pode-se concluir que o projeto conseguiu atender os requisitos propostos e mitigar os diversos problemas apresentados. A sua implantação foi bem recebida pelo squad escolhido e sua difusão não é uma tarefa complicada, dado sua fácil utilização e vantagens imediatas. Inclusive, ao longo do projeto foi tomado o cuidado de se extrair os componentes altamente acoplados com características específicas do Nubank, de modo que a implantação da solução até mesmo em outras empresas fosse possível sem muitas modificações.
	
%
% \\[3\baselineskip]
%
\textbf{Palavras-Chave} -- Microsserviço, Docker, Kubernetes, Computação em Nuvem, Distributed Tracing.
\end{resumo}


% ========== Abstract ==========
\begin{abstract}
Abstract...
%
\\[3\baselineskip]
%
\textbf{Keywords} -- Word, Word, Word, Word, Word.
\end{abstract}


% ========== Listas (opcional) ==========
\listadefiguras
\listadetabelas

% ========== Listas definidas pelo usuário (opcional) ==========
%\begin{pretextualsection}{Lista de símbolos}

%Lista de símbolos...

%\end{pretextualsection}

% ========== Sumário ==========
\sumario



% ========== Elementos textuais ==========

%\part{Introdução}
	
\chapter{Introdução}
	\section{Objetivo}
	%% O que o seu projeto resolve?
	O objetivo deste trabalho é criar um ambiente e um ferramental para acelerar a iterações no desenvolvimento de microsserviços em uma arquitetura de larga escala.
	\section{Motivação}
	%% Por que fazer um trabalho?
	A motivação desse projeto vem de alguns fatores. O primeiro é o interesse e a familiaridade do grupo quanto ao desenvolvimento de microsserviços provenientes da experiência adquirida nos estágios na Nubank, e o reconhecimento dos benefícios e dificuldades essa arquitetura. Outro fator importante é a constatação de que, com o crescimento das aplicações em nuvem computacional, a necessidade e urgência de uma arquitetura distribuída aumenta, e a carência de ferramentas para conter suas dificuldades se torna um problema cada vez mais importante.
	
	Com isso, foi possível a identificação de um problema relativamente complexo de Engenharia de Software que ainda não teve a devida atenção no mercado, e uma oportunidade para aplicação e aprofundamento do nosso conhecimento de processo de desenvolvimento de software. Nós queríamos, então, criar uma proposta de solução para um problema real ainda em discussão.
	\section{Justificativa}
	%% Por que fazer esse trabalho? 
	%% 1. O tema é necessário (debugging microservices)
	O crescimento da arquitetura de microsserviços é notório e pode ser percebido de várias formas. Tanto no mercado quanto na academia, a discussão só tem crescido, com cada vez mais empresas grandes decidindo adotar essa tecnologia, tais como Uber e Netflix. É possível notar também um crescente número de livros que tratam sobre o assunto, como \textit{Production-Ready Microservices} da Susan J. Fowler\cite{productionreadyms} e \textit{Microservices Patterns} de Chris Richardson\cite{mspatterns}. Esse crescimento permitiu a escalabilidade dessas empresas, mas também veio com um custo: a crescente complexidade.
	
	É nesse contexto que o Nubank se encontra e faz parceria neste trabalho. O Nubank é uma fintech brasileira que conta com cerca de 200 engenheiros, trabalhando diariamente em mais de 200 microsserviços para atender os mais de 5 milhões de clientes ativos em seus diversos produtos. A empresa é referência nacional e mundial em tecnologia, devido a sua arquitetura de software moderna, baseada em microsserviços. Porém, as implicações negativas deste modelo já estão se manifestando na empresa há algum tempo, prejudicando a produtividade das equipes. Assim, tivemos a oportunidade de firmar essa parceria e trabalharmos em um contexto real, para resolver uma carência crescente na empresa.
	
	No entanto, este trabalho foi feito de tal forma que, com algum esforço de implantação, as ferramentas desenvolvidas possam ser usufruídas por outras empresas que tenham características de arquitetura semelhantes. Um estudo feito na Universidade de Brighton, no Reino Unido, indica que dentre 33 publicações referentes à arquitetura de microsserviços, o desafio mais citado é referente a comunicação e integração dos microsserviços.\cite{systematicmapping}
	%% 4. Há evidência de que outros contextos podem se beneficiar desse projeto.
	%%\cite{fowlermicroservices}
	\section{Organização do Trabalho}
	%% Como ler esse texto?
	
\chapter{Aspectos Conceituais}
    \section{Scrum}
    \cite{essentialscrum}
    TODO

	\section{Cloud Computing}
	Computação em Nuvem (do Inglês \textit{Cloud Computing}) é segundo a NIST \footnote{National Institute of Standards and Technology, https://www.nist.gov/} um modelo para prover um acesso de rede a um grupo compartilhado (\textit{shared pool}) de recursos computacionais (recursos como capacidade de rede, servidores, armazenamento, aplicações e serviços) de forma ubíqua, prática e sob demanda.

Tal acesso deve ser rapidamente provisionado e lançado com o mínimo de gerenciamento e interação com o provedor de serviços por parte da aplicação.

O modelo de computação em nuvem deve possuir algumas características básicas, que estão descritas na seção seguinte.

\subsection{Características básicas de Cloud Computing}

A NIST define 5 características essenciais do modelo de Cloud Computing:
\begin{itemize}
	\item Serviço sob demanda: Um consumidor pode provisionar unilateralmente capacidades computacionais, como tempo de servidor e armazenamento de rede, conforme for necessário, sem qualquer interação humana com o provedor de serviço;
	\item Agrupamento de recursos: Os recursos de computação do provedor são agrupados para atender a vários consumidores usando um modelo "multi inquilino", com diferentes recursos físicos e virtuais dinamicamente atribuídos e reatribuídos de acordo com a demanda do consumidor. Existe uma sensação de independência de localização pois o cliente geralmente não tem controle ou conhecimento sobre a localização exata dos recursos fornecidos, mas pode ser capaz de especificar a localização em um nível de abstração (por exemplo, país, estado ou datacenter). Exemplos de recursos incluem armazenamento, processamento, memória e largura de banda de rede.
	\item Amplo acesso à rede: Os recursos estão disponíveis na rede e são acessados por meio de mecanismos que promovam o uso por plataformas heterogêneas por clientes em diversos dispositivos (por exemplo, telefones celulares, tablets, laptops e estações de trabalho). Esta característica promove o conceito de computação ubíqua, isto é, em toda parte, onipresente.
	\item Elasticidade rápida: Os recursos podem ser provisionados e liberados elasticamente, em alguns casos automaticamente, proporcionando uma escalabilidade crescente ou descrescente conforme a demanda. Os recursos disponíveis normalmente aparentam ser ilimitados para o consumidor, podendo ser requisitidados em qualquer quantidade e a qualquer momento.
	\item Serviço mensurável: Os sistemas em nuvem controlam e otimizam automaticamente o uso de recursos, aproveitando-se de uma capacidade de medição em um nível de abstração apropriado ao tipo de serviço (por exemplo, armazenamento, processamento, largura de banda e contas de usuário ativas). O uso de recursos pode ser monitorado, controlado e reportado, gerando transparência tanto para o fornecedor e consumidor do serviço utilizado.
\end{itemize}

\subsection{Modelos para Cloud Computing}

Este capítulo introduz brevemente os modelos de serviço de cloud computing que podem ser adotados por um provedor e os modelos de \textit{deployment}, nas secções seguintes.

\subsection{Modelos de serviços}

A teoria por trás dos serviços de computação em nuvem abrange três elementos principais: software, plataforma e infraestrutura. Temos os seguintes modelos de serviço:

\begin{itemize}
  \item \textbf{SaaS, Software as a Service} ("Software como um serviço") 

  Neste modelo é oferecido ao consumidor o uso de aplicações de um provedor que rodam sobre uma infraestrutura em nuvem. Estas aplicações são acessíveis a partir de vários dispositivos clientes por meio de uma interface simples, como um navegador da web, ou uma interface de por meio de um programa (mobile ou desktop). 

  O consumidor não gerencia ou controla a infraestrutura de nuvem por trás da aplicação, incluindo rede, servidores, sistemas operacionais, armazenamento ou capacidade da aplicação individual. São disponibilizadas apenas configurações do aplicativo específicas para aquele usuário individual.

  Alguns exemplos de SaaS são serviços de \textit{webmail}, \textit{streaming} de vídeos, conversão de arquivos e trabalho colaborativo com arquivos. Este modelo não será mais detalhado neste trabalho.

  \item \textbf{PaaS, Platform as a Service} ("Plataforma como um serviço") 

  A capacidade fornecida ao consumidor é de implantar na nuvem aplicações criadas por meio de linguagens de programação, bibliotecas, serviços e ferramentas suportadas pelo provedor. Tais aplicações podem ser criadas pelo próprio consumidor, ou consumidas por este.

  Assim como no modelo de SaaS, o consumidor geralmente não gerencia ou têm controle sobre a infraestrutura de nuvem por trás, incluindo rede, servidores, sistemas operacionais, ou armazenamento. Porém o consumidor as tem controle sobre os aplicativos implantados e possivelmente sobre definições de configuração para o ambiente de hospedagem do aplicativo.

  Como exemplos de provedores no mercado temos \textit{IBM Bluemix}, \textit{Heroku}, e \textit{Windows Azure Cloud}.

  \item \textbf{IaaS, Infrastructure as a Service} ("Infraestrutura como um serviço") 

  A capacidade oferecida ao consumidor é provisionar processamento, armazenamento, redes e outros recursos fundamentais de computação onde o consumidor é capaz de implantar e executar software arbitrário, incluindo-se sistemas e aplicações. O consumidor não gerencia nem controla a infraestrutura de nuvem por trás, mas tem controle sobre sistemas operacionais, armazenamento e aplicativos implantados. Possivelmente possui também um controle limitado de componentes de rede (por exemplo, firewalls de host). Geralmente acompanha serviços de máquinas virtualizadas.

  Alguns exemplos de provedores no mercado são \textit{Amazon Web Services}, \textit{Microsoft Azure}, \textit{Google Cloud} e \textit{VMware Cloud on AWS}. 
\end{itemize}

\subsection{Modelos de implantação}
Os modelos de implantação (\textit{deployment models}) a seguir delimitam as formas pos\-sí\-veis de tarifação dos serviços, as possíveis localizações da infraestrutura física e o público de escopo. São eles:

\begin{itemize}
  \item \textbf{Nuvem privada}: A infraestrutura de nuvem é disponibilizada para uso exclusivo por uma única organização, compreendendo vários consumidores (\textit{business units}). Pode ser propriedade e gerenciada pela própria organização, um terceiro ou alguma combinação de ambos, e pode existir dentro ou fora das instalações da organização.
  \item \textbf{Nuvem comunitária}: A infraestrutura em nuvem é de uso exclusivo por uma comunidade de consumidores de organizações que compartilham mesmos interesses (por exemplo, missão, requisitos de segurança, políticas e considerações de conformidade). Pode ser de propriedade e administrada por uma ou mais organizações da comunidade, um terceiro, ou alguma combinação de ambos, e pode existir dentro ou fora das instalações.
  \item \textbf{Nuvem pública}: A infraestrutura de nuvem é para o uso aberto pelo público em geral. Pode ser propriedade ou gerenciada por uma organização comercial, acadêmica ou governamental, ou alguma combinação destes. Existe dentro das instalações do provedor de nuvem.
  \item \textbf{Nuvem híbrida}: A infraestrutura de nuvem é uma composição de duas ou mais infraestruturas de nuvens distintas (privadas, comunitárias ou públicas) que permanecem como entidades únicas, mas unidas por tecnologia padronizada ou proprietária permitindo portabilidade de dados e aplicações (por exemplo, \textit{cloud bursting} para balanceamento de carga entre nuvens).
\end{itemize}

	\section{Docker}
	\subsection{Breve história das tecnologias de contêineres}
	A história dos Contêineres começa em 1979 no Unix L7. Nele foi introduzido a chamada de sistema (\textit{system call}) \textit{chroot} capaz de mudar o diretório raiz de um processo e de seus processos filhos para um novo local no sistema de arquivos. Este avanço foi o início do conceito de isolamento de processos, pois limitava o acesso de cada processo ao sistema de arquivos. 

	Em 2000, surgiu o FreeBSD Jail, que permitia a administradores particionar um sistema FreeBSD em vários sistemas menores isolados e independentes, chamados de “\textit{jails}”. O sistema é similar ao \textit{chroot}, mas incluiu recursos de isolamento adicionais em diversos aspectos do sistema operacional, como por exemplo a atribuição de um endereço de IP diferente para cada \textit{jail}. \cite{abriefhistoryofcontainers}

	Em 2001, foi lançado o Linux VServer que, assim como o FreeBSD Jail, também é um mecanismo de \textit{jail} que pode particionar recursos (sistema de arquivos, endereços de rede, memória) em um sistema computacional. Isso é realizado por meio de níveis de isolamento do \textit{kernel}. Cada partição é chamada \textit{security context} e o sistema virtualizado dentro dele é chamado de \textit{virtual private server}. \cite{linuxvserver}

	Em 2004, foi lançado o Solaris Zones para sistemas x86 e SPARC. Cada \textit{zone} age como um servidor virtual completamente isolado dentro de uma única instância. Existem dois tipos de \textit{zones}: zonas globais (\textit{Global Zones}) e não-globais (\textit{Non-Global Zones}). A zona global é o ambiente de SO tradicional e é a área onde o SO Solaris está instalado. Todas as operações do sistema, como instalações, inicializações e desligamentos são feitas na zona global. As zonas não-globais, comumente chamadas somente de zonas, tem seus recurso e limites definidos pela zona global a que pertencem  \cite{introductiontosolariszone}

	Em 2005 a empresa Virtuozzo lançou o OpenVZ, que utiliza o \textit{kernel} do Linux para fornecer virtualização, isolamento, gerenciamento de recursos e \textit{checkpointing}. Cada contêiner OpenVZ possui um sistema de arquivos isolado, usuários e grupos de usuários, uma árvore de processos, rede, dispositivos e comunicação entre processos. Uma desvantagem da solução é que seu funcionamento depende da aplicação de um \textit{patch} no \textit{kernel} do Linux. \cite{openvz}

	Em 2006 engenheiros da Google desenvolveram o Process Containers, projetado para limitar, contabilizar e isolar o uso de recursos computacionais (CPU, memória, I/O do disco, rede) de uma coleção de processos. Um ano depois o projeto foi renomeado para Control Groups (\textit{cgroups}) e foi adicionado ao \textit{kernel} do Linux na versão \textit{2.6.24}.

	Em 2008 surgiu o LXC (LinuX Containers), que foi a primeira e mais completa implementação de um gerenciador de contêineres Linux. Foi implementado utilizando \textit{cgroups} e Linux \textit{namespaces} e funciona no \textit{kernel} do Linux sem a necessidade da aplicação de \textit{patches}.
	
	Em 2011 a empresa CloudFoundry iniciou o projeto Warden, que utilizava LXC em suas primeiras implementações, porém depois foi substituído por soluções próprias da empresa. Warden roda em formato \textit{daemon} e pode isolar ambientes em qualquer sistema operacional. Além disso, provê uma API para o gerenciamento de \textit{cgroups}, \textit{namespaces}, ciclo de vida dos processos e dos contêineres em diversos \textit{hosts} através de um modelo cliente-servidor.

	Finalmente, em 2013, surgiu o Docker. Neste momento contêineres cresceram muito em popularidade, juntamente com o Docker em si.
	Assim como o Warden, o Docker utilizou LXC em seus primeiros estágios mas logo trocou por uma solução própria para gerenciamento de contêineres: o \textit{libcontainer}.
	O Docker se destacou de seus concorrentes por oferecer um ecossistema completo para o gerenciamento de contêineres, que será detalhado mais adiante.
	
	\subsection{Contêineres e Máquinas virtuais}
	
	A virtualização é a tecnologia que permite a criação de diferentes ambientes computacionais, chamados de virtuais por simular a interface que é esperada por um sistema operacional.
	
	Um dos principais componentes da arquitetura é o \textit{Hypervisor}. Ele gerencia a distribuição dos recursos computacionais na máquina física (armazenamento, processamento e memória) entre as várias máquinas virtuais, além de fornecer um isolamento entre elas. Ele é um componente que fica entre o \textit{hardware} e a máquina virtual e é necessário para o processo de virtualização.
	Entre os gerenciadores de máquinas virtuais mais populares no mercado, pode-se citar VMWare vSphere, VirtualBox, Xen, Hyper-V e KVM.

	No baixo nível, um contêiner é apenas um conjunto de processos que são isolados do resto do sistema. No caso do Docker, os contêineres compartilham o \textit{kernel} do sistema operacional hospedeiro e, frequentemente, os binários e bibliotecas também. Todos os componentes compartilhados são \textit{read-only}. Este compartilhamento de componentes reduzem a necessidade de se replicar código do sistema operacional, e isso significa que um único servidor pode executar múltiplos contêineres com uma única instalação do sistema operacional.

	Diferentemente, uma máquina virtual é constituída do espaço de usuário juntamente com o espaço do \textit{kernel} de um sistema operacional e o \textit{hardware} é virtualizado. Cada máquina virtual tem um sistema operacional e suas aplicações e elas compartilham entre si o \textit{hardware} do computador hospedeiro.

	Ambas as tecnologias provém ambientes isolados para execução de aplicações e podem ser utilizadas para empacotar e distribuir \textit{software}.

	Dado o menor número de camadas entre a aplicação e o \textit{hardware},  os contêineres tendem a ser mais leves e mais rápidos, tornando-os mais práticos para os ciclos de desenvolvimento e implantação de serviços. Comparativamente, o tempo de inicialização de uma máquina virtual é muito maior do que a de um contêiner equivalente, além de o espaço ocupado em disco ser uma ordem de magnitude maior. \cite{whatsthediffvmvscontainers}
	
	\begin{figure}[htb]
		\caption{\label{fig_circulo}Diferenças entre VMs e Contêiners}
		\begin{center}
    		\includegraphics[scale=0.20]{pictures/vms.png}
    		\includegraphics[scale=0.20]{pictures/containers.png}
		\end{center}
		\legend{Fonte: https://www.backblaze.com/blog/vm-vs-containers/}
	\end{figure}
	
	Ambos têm vantagens e desvantagens, e a decisão entre um outro varia dependendo dos casos de uso específicos, mas pode-se utilizar as seguintes regras como um ponto de partida:
	
	Máquinas virtuais são melhores para executar aplicações que necessitam de todos os recursos e funcionalidades do sistema operacional ou quando há uma variedade de sistemas operacionais para se gerenciar.
	
	Contêineres são uma escolha melhor quando a maior prioridade é maximizar o número de aplicações sendo executadas em um número mínimo de servidores.
	
	\section{Kubernetes}
	Kubernetes é um projeto de código aberto da Google, que possui mais de 1800 contribuintes e ganha cada vez mais atenção no mundo de operação e desenvolvimento de software. 
	O Google, dado a escala de sua operação, sofria com problemas com o gerenciamento de muitas máquinas virtuais. 
	Assim, o Google precisou repensar como lidar com esse problema, o que, depois de anos, levou ao gerenciador e escalonador de contêineres chamado Kubernetes.

	Para entender melhor a necessidade de um gerenciador tal como o Kubernetes, é necessário dar um passo atrás e olhar para as vantagens e desvantagens dos contêineres.
	Contêiners são feitos para serem leves, rápidos, mas de duração curta e frágeis.
	Assim, eles trocaram a resiliência de uma máquina virtual pela velocidade e leveza. Isso requer que contêineres rodem em um ambiente onde em caso de falha ou mudança de carga, esse ambiente garanta a substituição desses contêineres e gerencie eventuais mudanças de rede e recursos de memória do cluster.
	
	\section{Programação Funcional}
	
	Como o próprio nome diz, a programação funcional surge de funções matemáticas, mais especificamente do cálculo lambda. Programação funcional é um paradigma de programação assim como Orientado a Objeto ou Imperativo. As características mais marcantes desse paradigma são a presença de imutabilidade de dados e estados, funções serem tratadas como valores como quaisquer outros tipos (inteiros, strings, etc...), transparência referencial e separação de efeitos colaterais.
	As linguagens de programação podem ser puramente funcionais, ou parcialmente, isso é, contém elementos desse paradigma porém não se limitam a ele, ou fazem pequenos desvios em prol da usabilidade.
	
	\section{Microsserviços}
	
	\section{HTTP}
	
	\section{GraphQL}
	
	\section{Arquitetura Hexagonal}
	
	Também conhecida com Arquitetura de \textit{Ports and Adapters} é um modelo de arquitetura de software em camadas que presa pela separação entre domínio e lógica da aplicação com comunicação e interação com o mundo exterior. Esse modelo possui as seguintes camadas:
	
	\begin{itemize}
	    \item Port
	    \item Adapter
	    \item Controller/Application
	    \item Domain/Logic
	\end{itemize}
	
	Sendo as responsabilidades de cada camada as seguintes:
	
	\textbf{Ports}: São a camada responsável por realizar o interfaceamento com algum tipo de IO, seja HTTP, Mensageria, Banco de Dados, ou qualquer outro.
	
	\textbf{Adapters}: Camada responsável por realizar a adaptação e transformação entre dados de um modelo do domínio interno para uma representação a ser usada externamente para alguma porta.
	
	\textbf{Controller/Application}: Tem o papel de controlar a interação e chamadas entre as portas junto as funcionalidades do domínio da aplicação.
	
	\textbf{Domain/Logic}: Lógica e modelos internos e específico da aplicação, contém a lógica principal do serviço.
	
	\begin{figure}[htpb]
	    \caption{Diagrama de Arquitetura Hexagonal}
	    \begin{center}
	        \includegraphics[scale=0.6]{pictures/hexagonal1.png}
	    \end{center}
	    \label{fig:hexagonal1}
	    \legend{Fonte: https://lmonkiewicz.com/wp-content/uploads/2017/04/hexagonal-e1491766585240.png}
	\end{figure}

	A grande possibilidade desse modelo é que ele permite que se tenham diversas portas e adaptadores diferentes para um mesmo domínio/lógica da aplicação, como o diagrama abaixo mostra.
	
	Essa arquitetura é muito interessante para microsserviços pois permite criar um desacoplamento de forma natural e da grandes possibilidades de meios de comunicação e interação dos serviços entre si.
	
	\section{Git}
	
	Git é um sistema de controle de versões distribuído amplamente utilizado em desenvolvimento de software. o Git se organiza através de repositórios que podem ser clonados e editados localmente pelo usuário e então sincronizados com um servidor remoto, publicando as alterações. Todo o histórico de alterações é mantido nesse processo sem perda de informações.
	Alguns conceitos importantes de serem destacados no funcionamento do Git para o melhor entendimento desse projeto são os seguintes:
	
	\textbf{Repositório}
	\newline
	Corresponde a um diretório de arquivos gerenciado pelo Git.
	
	\textbf{Commit}
	\newline
	É uma consolidação de um conjunto de alterações realizado no repositório Git. Representa um ponteiro para um estado específico (uma versão).
	
	\textbf{Branch}
	\newline
	Branch é um ponteiro movél que aponta para um determinado commit. Branches criam a ideia de uma árvore de caminhos em um repositório apontam sempre para o commit mais recente de uma bifurcação de mudanças.
	
	\textbf{HEAD}
	\newline
	HEAD é um ponteiro que aponta para para o branch ou commit atual que está em uso no repositório local.
	
	\textbf{FETCH\_HEAD}
	\newline
	Um ponteiro efêmero que aponta para a última referência buscada por um fetch.
	
	\textbf{Staging}
	\newline
	Área do Git onde as alterações que vão entrar no próximo commit ficam
	
	\begin{figure}[htbp]
		\caption{\label{fig_git1}Anatomia do Git}
		\begin{center}
		\includegraphics[scale=0.4]{pictures/git.png}
		\end{center}
		\legend{Fonte: \url{https://raw.githubusercontent.com/UnbDroid/AprendendoGithub/master/images/git.png}}
	\end{figure}
	
	Para realizar a sincronização entre repositórios locais e remotos o Git possibilita o uso de diversos protocolos de rede, temos entre eles principalmente: HTTP(S), FTP, rsync ou SSH.
	
	Durante o processo de uso do Git algumas ações são frequentemente utilizadas, e valem ser destacadas aqui, essas são:
	\begin{itemize}
    	\item \textbf{git init:} 
    	Inicia um repositório git vazio no diretório.
    	
    	\item \textbf{git clone:}
    	Cria um cópia de um repositório remoto localmente, acaba por fazer um download da estrutura remota para a maquina do usuário.
    	
    	\item \textbf{git fetch:}
	    Sincroniza o estado do repositório remoto com o local sem realizar alterações na \textit{working tree} do desenvolvedor. Baixa os dados existentes no repositório remote que não existem no computador do usuário.
	
    	\item \textbf{git checkout:}
    	Alinha o repositório local de acordo com a revisão ou branch especificado no comando.
    	
    	\item \textbf{git commit:}
    	O commit é o ato de criar um ponto no histórico do repositório contendo as mudanças que foram adicionas na área de staging.
    	
    	\item \textbf{git add:}
    	O comando \textit{add} é responsável por adicionar as mudanças especificadas na área de staging do git para serem comitadas em seguida.
    	
    	\item \textbf{git push:}
    	O push executa a ação de enviar os commits locais para o repositório remoto especificado.
    	
    	\item \textbf{git merge:}
    	Atualiza os arquivos na working tree para corresponderem ao especificado no comando. O merge também pode acabar atualizando o HEAD do branch atual.
    	
    	\item \textbf{git pull:}
    	Esse comando realiza a atualização do repositório local a partir das mudanças realizadas no repositório remoto. De forma geral ele acaba realizando um download dos commits mais recentes que estão presentes no remote. É uma combinação do git fetch com o git merge FETCH\_HEAD
	\end{itemize}
	\begin{figure}[htb]
		\caption{\label{fig_git2}Fluxo de trabalho em Git}
		\begin{center}
		\includegraphics[scale=1]{pictures/GIT2.png}
		\end{center}
		\legend{Fonte: \url{https://kevintshoemaker.github.io/StatsChats/GIT2.png}}
	\end{figure}

	
	\section{Distributed Tracing}
	
	Distributed Tracing, ou Rastreamento Distribuído, é uma técnica utilizada em sistemas distribuídos para conseguir acompanhar algum fluxo que acaba por interagir com diversos serviços. Muito utilizado para ajudar desenvolvedor em sessões de depuração afim de entender qual caminho de código está sendo executado e com quais parâmetros em um sistema complexo e distribuído. Geralmente esse sistema se compõe de um broker central para onde as métricas e dados de tracing são enviados pelos serviços, e um conjunto de código que roda em todos os serviços, responsável por realizar a amostragem e enviar esses dados para o broker principal. Enquanto os brokers esperam receber mensagens representando eventos de entrada ou saída dos serviços através de um processo coletor, as bibliotecas se encarregam de enviar essa menagem e também propagar informações de rastreabilidade para as próximas interações com outros serviços. Podemos ver um digrama exemplificando a arquitetura de um Distributed Tracing nas figuras \ref{fig_tracing_concept} e \ref{fig_tracing_components}
	
	\begin{figure}[htb]
		\caption{\label{fig_tracing_concept}Anatomia de um Distributed Tracing}
		\begin{center}
		\includegraphics[scale=0.5]{pictures/tracing_concept.png}
		\end{center}
		\legend{Fonte: \url{https://cdn-images-1.medium.com/max/838/1*NuwuCvqZHLBJcJycRr1HTw.png}}
	\end{figure}
	
	\begin{figure}[htb]
		\caption{\label{fig_tracing_components}Componentes de um Distributed Tracing}
		\begin{center}
		\includegraphics[scale=0.95]{pictures/distributed-tracing-components.png}
		\end{center}
		\legend{Fonte: \url{http://blog.newrelic.com/wp-content/uploads/Distributed-tracing-components.png}}
	\end{figure}
	
	Um dos primeiros Distributed Tracers que foi desenvolvido, foi o Dapper \cite{googledapper}, pela Google em meados de 2010. Com a abertura do código do Dapper outras empresas acabaram se interessando pelo projeto e funcionalidades e criaram suas próprias versões de tracers, entre eles alguns dos mais famosos: Zipkin\cite{zipkin}, pelo Twitter, e Jaeger\cite{jaegerarch}, pela Uber. Com o surgimento de novos tracers no mercado, a industria entrou em busca de um padrão para esse tipo de software, originando-se o OpenTracing\cite{opentracing}. OpenTracing é um padrão desenvolvido afim de definir normas e regras e padrões para implementação de Distributed Tracers. Nela são descritos estratégias para se realizar a identificação de informações gera mente importantes e o formato do tráfego de dados entre os serviços e os brokers.
	
	Grande parte do valor dos Distributed Tracing vem de suas ferramentas analíticas, que facilitam a vida do desenvolvedor e permitem com que ele faça análises de forma rápida e eficiente nos sistemas. Geralmente essas ferramentes vem junto com uma aplicação de Frontend que consegue exibir fluxos e montar gráficos. Entre eles o Flamegraph é muito utilizado para visualizarmos como a comunicação se aprofunda e se propaga na rede, uum exemplo de Flamegraph do Zipkin pode ser visto na figura \ref{fig_zipking_sample}. Outro tipo de visualização muito útil é a de mapa de Topologia de servços, que nada mais é que um grafo representando as interações entre diversos serviços, temos um exemplo na figura \ref{fig_topology_map}
	
	\begin{figure}[htb]
		\caption{\label{fig_zipking_sample}Exemplo de Flamegraph do Zipkin}
		\begin{center}
		\includegraphics[scale=0.16]{pictures/zipkin-sample.png}
		\end{center}
		\legend{Fonte: \url{http://callistaenterprise.se/assets/blogg/build-microservices-part-7/Zipkin-sample.png}}
	\end{figure}
	
	\begin{figure}[htb]
		\caption{\label{fig_topology_map}Exemplo de Mapa de Topologia de Serviços}
		\begin{center}
		\includegraphics[scale=0.16]{pictures/service_topology_map.png}
		\end{center}
		\legend{Fonte: \url{https://blog-assets.risingstack.com/2016/May/Distributed_transaction_tracing_with_service_topology_map_trace_by_risingstack-1462456507669.png}}
	\end{figure}
	
	\subsection{OpenTracing}
	
	Nessa seção iremos entender um pouco melhor como se organiza e os principais conceitos estabelecidos pelo padrão OpenTracing. Entre eles vamos entender como é feita a correlação entre eventos enviados pelos serviços e quais os mecanismos padrões utilizados para que isso seja efetivamente realizado por aplicações reais.
	
	
 
\chapter{Tecnologias Utilizadas}
	\section{Clojure}
	
	Clojure é uma linguagem de programação dinâmica e funcional. Sendo um dialeto de LISP que roda na JVM, é uma linguagem compilada, mas que mantém todas características dinâmicas a ser utilizadas em Runtime. Possui compatibilidade e interoperabilidade com todo ecossistema Java e de outras linguagens que rodem na JVM. Clojure enfatiza o uso de estruturas de dados imutáveis e de a filosofia de Code is Data, com um sistema poderoso de macros e de estruturas de dados mutáveis Thread Safe quando necessário. \cite{clojurerationale}
	
	Clojure é a principal linguagem de programação utilizada no Nubank, e também é muito familiar para o grupo, além de apresentar características interessantes para o desenvolvimento do projeto. como a grande habilidade para lidar com problemas de concorrência de forma segura e eficiente.
	
	Dentro do desenvolvimento do projeto Clojure foi utilizada como uma das principais linguagens de programação para serviços de Backend. Um dos recursos que torna Clojure especialmente interessante é a possível interação em tempo real com o código através de um REPL (Read Eval Print Loop), algo que foi utilizado em um dos módulos do projeto como será descrito mais a frente. Além disso a familiaridade dos desenvolvedores do Nubank com a linguagem foi um fator decisivo para que o projeto pudesse continuar a ser mantido por mais pessoas no futuro.
	
	\begin{figure}
	    \centering
	    \includegraphics[scale=0.1]{pictures/clojure_logo.png}
	    \caption{Logo Clojure}
	    \legend{Fonte: \url{https://cdn-images-1.medium.com/max/1200/1*eLqeIits5crU3G5b9LMEyg.png}}
	    \label{fig:logo_clojure}
	\end{figure}
	
	\section{Javascript}
    	\subsection{Typescript}
    	\subsection{NodeJS}
    	\subsection{React}
    	\subsection{Electron}
	\section{ZeroMQ}
	\section{Docker}
	\section{Kubernetes}
	

\chapter{Metodologia do Trabalho}
\section{Introdução}
A nossa metodologia de trabalho foi uma adaptação da proposta de (Bittner, 2002)\cite{usecases}, ODP() e Scrum\cite{essentialscrum}. Tendo entendido o problema e o \textit{stakeholders} (primeira parte), Unimos a completeza e formalidade da definição de requisitos funcionais identificáveis por casos de uso e ODP para a concepção inicial do produto (segunda parte), inserindo esses conhecimentos num \textit{framework} de \textit{Scrum}, adaptado para o nosso contexto (terceira parte).
\begin{enumerate}
    \item Definição de stakeholders e contexto do problema
    \item Concepção inicial do produto
    \item Execução interativa
\end{enumerate}

\section{Definição de Stakeholders e contexto do problema}
Um stakeholder é uma pessoa ou organização com direitos ou interesse com respeito ao sistema ou às propriedades dele. Os \textit{stakeholders} dão forma ao software, gerando oportunidades e limitações ao desenvolvimento, sendo também a fonte de requisitos do sistema. Os desenvolvedores podem propor requisitos, mas cabe aos \textit{stakeholders} acatar as sugestões ou não.
A tabela \ref{tab:roles} mostra os \textit{stakeholders} de nosso projeto, e em seguida temos uma descrição das dores e influência de cada um na nossa solução. O método de alinhamento de expectativas está descrito na próxima seção.

\begin{table}[ht]
\centering
\begin{tabular}{l l}
Entidade & Papel \\
\hline
Leonardo Iacovini   &   Desenvolvedor  \\
Luiz Gustavo &  Desenvolvedor  \\
Rafael Leal   &  Desenvolvedor \\
Rafael Correia   &  Desenvolvedor \\
Rafael Ferreira   &  Stakeholder \\
Integrantes da equipe de platform   &  Stakeholder \\
Integrantes da equipe de lending   &  Stakeholder 
\end{tabular}
\caption{Papéis de cada entidade ao longo do projeto.}
\label{tab:roles}
\end{table}
\subsection{Detalhamento dos stakeholders e influências}
TBD

\section{Concepção inicial do produto}
\subsection{Casos de Uso}
\subsection{ODP}
\subsection{Outras considerações}

\section{Execução Interativa}
Simplificamos muitas das práticas do \textit{scrum} usual para lidar com as limitações e o menor escopo do projeto, se comparado com desenvolvimento de software empresarial de larga escala.
Usamos \textit{sprints} de duas semanas cada, correspondente ao período de implementação do que foi definido como prioridade, a partir do \textit{backlog}. Este, por sua vez, fora definido em cada uma das reuniões de \textit{sprint planning}, usadas por nós para priorizar tarefas do \textit{backlog}, identificar os maiores problemas e travas para prosseguir na implementação e reorganizar e/ou atualizar os \textit{milestones}.\par
Trabalhamos três vezes por semana, fazendo sessões de \textit{pairing} para codificar a solução e discuti-la e fazer \textit{live-testing} em reuniões de 4 horas a 6 horas de duração, em média, dependendo da dificuldade do problema que estávamos tentando resolver, ou disponibilidade dos integrantes do grupo.
Como estávamos todos na mesma sala discutindo e implementando, ficou mais simples de difundir o conhecimento da arquitetura e das decisões de projeto para cada integrante, e problemas técnicos ou arquiteturais foram resolvidos com bastante eficiência, pois os outros integrantes estavam ao lado, caso qualquer dúvida ocorresse. Devido ao teor organizacional dessas reuniões de projeto que fizemos, vimos que as \textit{daily meetings} propostas pela metodologia de \textit{scrum} seriam supérfluas para nosso método de trabalho, e acabamos não adotando-as.
Não coincidindo necessariamente com o final da \textit{sprint}, fizemos reuniões que uniram as idéias de \textit{sprint reviews} e \textit{sprint retrospective} para mostrar \textit{demo} aos nossos \textit{stakeholders}, pegar feedback e reorganizar o \textit{backlog} segundo o feedback dos mesmos, além de identificar o que deu errado, para poder se preparar melhor para o próximo período de trabalho. 
Vale mencionar também que antes de termos a idéia do produto formalizada também fizemos algumas reuniões com um de nossos \textit{stakeholders} (Rafael Ferreira) que nos deu grande ajuda para entendermos do que se tratava o produto, além de proporcionar feedbacks quanto ao andamento do projeto, soluções técnicas e \textit{milestones}.
Escolhemos não ter \textit{scrum master} pois o papel do mesmo de filtrar forças distrativas no nosso trabalho não se mostrou necessário, e também não tivemos \textit{Product Owner} pois o nosso \textit{backlog} foi feito de forma conjunta, pelos 4 desenvolvedores e a terceirização da comunicação com os \textit{stakeholders} não foi necessária, pois tínhamos liberdade e disponibilidade para falar com os mesmos diretamente, quando precisássemos.

\section{Utilitários}
Aqui apresentaremos algumas ferramentas auxiliares que utilizamos para organizar o andamento do projeto.

\subsection{GitHub}
GitHub \cite{github} é um servidor de \textit{git}.

\subsection{Clubhouse}
Clubhouse \cite{clubhouse} é uma ferramenta online de gerenciamento de projetos de software, provendo funcionalidades interessantes para criar \textit{tasks}, definir \textit{milestones}, verificar o andamento do projeto com \textit{boards} e alguns gráficos. Também provê integração com o \textit{GitHub}.

\begin{figure}[htb]
    \caption{Board do Formicarium no Clubhouse}
    \begin{center}
        \includegraphics[scale=0.20]{pictures/clubhouse-fmc.png}
    \end{center}
    \label{fig:clubhouse}
    \legend{Fonte: os autores - 2018-11-10}
\end{figure}

\subsection{Slack}
Slack \cite{slack} \textit{software} para equipes que proporciona mensageria instantânea, canais de conversa, \textit{workspaces} e muitas integrações (por exemplo, utilizamos a do \textit{GitHub} para acompanhar os nossos repositórios).

\chapter{Especificação de Requisitos do Sistema}
    Escolhemos especificar os requisitos de sistema do nosso projeto seguindo o modelo de referência ODP, pois ele apresenta uma forma de simplificar a descrição de sistemas complexos por meio dos seus Pontos de Vista.\cite{odppart1} Sabíamos também que gostaríamos se seguir alguns princípios de projeto, descritos na Tabela \ref{principios_de_projeto}. Esses princípios foram resultado de conversas com engenheiros de software e interessados no projeto, e nos ajudaram a guiar durante a definição dos requisitos de sistema.
    \begin{table}
        \centering
        \caption{Princípios de Projeto}
        \label{principios_de_projeto}
        \resizebox{\textwidth}{!}{%
        \begin{tabular}{|l|p{10cm}|}
            \hline
            Princípio de Projeto                 & Descrição \\ \hline
            Ambientes de curta duração           & O desenvolvedor deve ser capaz de criar e deletar ambientes com rapidez e facilidade                                 \\ \hline
            Visualização de fluxos complexos     & O desenvolvedor deve ser capaz de visualizar o resultado de suas requisições HTTP e mensagens Kafka                  \\ \hline
            Ambiente parecido com o local        & O desenvolvedor deve ter uma experiência de desenvolvimento similar com o ambiente de sua máquina                    \\ \hline
            Esconde complexidade de configuração & O desenvolvedor não deve precisar conhecer a configuração dos serviços que ele precisa disponíveis no ambiente dele. \\ \hline
        \end{tabular}
        }
        \legend{Fonte: os autores}
    \end{table}
	\section{Ponto de Vista da Empresa}
	    As empresas que podem se beneficiar do nosso projeto devem ter alguma semelhança com o processo de negócio de desenvolvimento e entrega de novas funcionalidades, descritos respectivamente nas Figuras \ref{fig:build-ci} e \ref{fig:automated-deploy}. O primeiro processo descreve como uma alteração de código por um desenvolvedor gera novas imagens Docker, que são guardadas em um catálogo chamado \textit{Docker Registry}. Exemplos de \textit{Docker Registry} são o DockerHub e o Quay.io. Já o segundo processo, descreve como uma imagem desses catálogo é implantada de forma automatizada pelo Servidor de Entrega Contínua.
	    \begin{figure}[htb]
    	    \centering
    	    \caption{Processo de Entrega Contínua - Construção da imagem Docker}
    	    \includegraphics[scale=0.7]{pictures/especificacao-de-requisitos/build-ci.png}
    	    \legend{Fonte: os autores}
    	    \label{fig:build-ci}
	    \end{figure}
	    \begin{figure}[htb]
    	    \centering
    	    \caption{Processo de Entrega Contínua - Implantação automatizada}
    	    \includegraphics[scale=0.7]{pictures/especificacao-de-requisitos/automated-deploy.png}
    	    \legend{Fonte: os autores}
    	    \label{fig:automated-deploy}
	    \end{figure}
	\section{Ponto de Vista da Informação}
	    O objetivo dessa seção é apresentar a organização das informações por todos os componentes do sistema. A Figura \ref{fig:info-contexts} representa os três principais contextos onde as informações são modeladas, e como é o fluxo de informações. 
	    \begin{figure}[htb]
    	    \centering
    	    \caption{Contextos de informação e seu fluxo}
    	    \includegraphics[scale=0.67]{pictures/especificacao-de-requisitos/information-contexts.png}
    	    \legend{Fonte: os autores}
    	    \label{fig:info-contexts}
	    \end{figure}
	    \subsection{Contexto da Empresa}
	        O contexto da empresa refere-se a uma base de dados pré-existente capaz de fornecer as configurações de uma aplicação dado o ambiente: teste, homologação e produção, tradicionalmente. Assim, a modelagem dessa base de dados pode ser arbitrária em relação ao sistema do Formicarium.
	    \subsection{Contexto do Formicarium}
	        \subsubsection{Servidor}
	        A Figura \ref{fig:info-server} representa a modelagem da configuração necessária para rodarmos uma aplicação. Note que uma aplicação pode possuir múltiplas interfaces e pode constituir por múltiplos contêineres. Isso permite maior flexibilidade na implantação e modelagem de aplicações.
	        \begin{figure}[htb]
        	    \centering
        	    \caption{Modelagem das Informações no Servidor}
        	    \includegraphics[scale=0.40]{pictures/especificacao-de-requisitos/info-server.png}
        	    \legend{Fonte: os autores}
        	    \label{fig:info-server}
	        \end{figure}
	        \subsubsection{Cliente}
	            
	\section{Ponto de Vista da Computação}
	    O Ponto de Vista da computação está diretamente ligado a distribuição. Não diz respeito aos mecanismos de interação, mas decompõe o sistem em objetos capazes de realizar funções e interagir por interfaces bem definidas \cite{odppart1}.
	    \subsection{Arquitetura de Referência}
	        A arquitetura deste projeto compartilha conceitos e mecanismos com arquiteturas de Plataformas como Serviço (\textit{Platform as a Service}), em particular a arquitetura do Heroku.
	        
	        "Heroku é uma plataforma de nuvem baseada em um sistema de contêineres gerenciado, com integração a serviços de dados e um poderoso ecossistema, para implantação e execução de aplicações modernas. O \textit{Heroku Developer Experience} é uma abordagem centrada na aplicação para entrega de software, integrada com as mais populares ferramentas e fluxos de trabalhos atuais." \citetext{herokuplatform}
	\section{Ponto de Vista da Engenharia}
	\section{Ponto de Vista da Tecnologia}

\chapter{Especificação de Requisitos de Qualidade}
Nessa seção mostraremos os requisitos de qualidade de software mais relevantes, utilizados no planejamento e implementação do projeto de software. Foram tomados como um subconjunto da especificação \cite{softquality}. Detalhamos os atributos de qualidade de produto, e qualidade de uso. 
\section{Qualidade de Produto}
   \subsection{Usabilidade}
         \subsubsection {Aprendabilidade}
          Os usuários do formicarium devem conseguir aprender sobre as principais features e operar nas features mínimas da plataforma dentro de um período estimado de 30 minutos de aprendizado. Essas features mínimas correspondem às funcionalidades descritas no Produto Mínimo Viável.\par
          \textbf{Método de avaliação:}
          número de novos usuários do formicarium que conseguiram fazer pelo menos uma operação em cada uma das features mínimas propostas pelo Produto Mínimo Viável $>$ 70\%
     \subsection{Segurança}
            \subsubsection{Responsabilização}
            Devemos manter o uso total contabilizado de tempo de máquinas na nuvem dividido por squad, para posterior contabilização de custos, proporcional ao uso.\par
            \textbf{Método de avaliação:}
            Ter essas informações disponíveis por meio de um relatório mensal.
            \subsubsection{Confidencialidade}
            O cluster de máquinas não deve ser acessível de fora da rede da empresa, para evitar vazamento de código proprietário, chaves da Amazon, etc.\par
            \textbf{Método de avaliação:}
            Verificação de rede por meio de relatórios semanais de um especialista em redes.
     \subsection{Portabilidade}
            \subsubsection{Instalabilidade}
            O sistema deve rodar em MacOS, Arch Linux, Ubuntu 16.04 LTS, Ubuntu 18.04 LTS.\par
            \textbf{Método de avaliação}
            Número de bug reports ligados à cada plataformas específica menor do que 5 por mês.
   
   \section {Qualidade de Uso}
     \subsection{Eficiência}
          Recursos de serviços da amazon gastos para o usuário criar ambientes e fazer deploy de serviços e devspaces.
               Otimizar o uso de máquinas usadas num deploy. Deixar o tipo de máquina ser escolhido pelo usuário, ou fazer uso ótimo e ir trocando o tipo de máquina segundo algum algoritmo de otimização. O mesmo vale para volumes.\par
              \textbf{Método de avaliação:}
              TBD
     \subsection{Eficiácia}
          Com que grau de acurácia o sistema permite que o usuário crie ambientes e deploy de microsserviços?
          \begin{itemize}
              \item O sistema deve ser capaz de criar ambientes.
              \item O sistema deve ser capaz de fazer deploy de microsserviços.
          \end{itemize}
          \textbf{Método de avaliação:}
              Taxa de erro em qualquer etapa de provisionamento de infraestrutura $<$ 5\%
     \subsection{Satisfação}
          Como podemos facilitar o dia a dia do desenvolvedor aumentando seu grau de satisfação durante o processo de desenvolvimento (tempo poupado, maior confiança nas alterações de código)\par
          \textbf{Método de avaliação}
          \begin{itemize}
              \item Número de reclamações/bugs reportados que atrapalharam o fluxo de desenvolvimento do desenvolvedor:  $<=$ 1 bug/semana
              \item Frequência de uso do Formicarium: $>=$ 1 vez por semana/squad
          \end{itemize}
     \subsection{Isenção de Risco Econômico}
          Os custos do cluster não devem crescer indefinidamente.\par
              \textbf{Método de avaliação:}
              Gastos monetários com o cluster $<=$ 50000 por mês\par
         \subsection{Cobertura do Contexto}
              O quão abrangente é o nosso produto no nicho que ele pretende influenciar?\par
              \textbf{Método de avaliação:} 
              90\% dos engenheiros do Nubank usam o formicarium pelo menos uma vez por semana.

\chapter{Projeto e Implementação}
\section{Casos de uso}
na figura \ref{fig_uc} podemos ver um ilustrativo dos casos de uso do formicarium. Em alto nível, podemos identificar 4 partes semânticas que um usuário enxergaria no sistema: 
\begin{description}
  \item[Devspaces] \hfill \\ Correspondente aos processos de gerenciamento de \textit{devspace}.
  \item[Events] \hfill \\ Correspondente à interação, filtros e visualização de eventos.
  \item[Flows] \hfill \\ Correspondente à manipulação de fluxos de negócio.
  \item[Services] \hfill \\ Correspondente à manipulação de serviços.
\end{description}

		\begin{figure}[ht!]
			\caption{\label{fig_uc}Casos de uso do Formicarium}
			\begin{center}
			\includegraphics[scale=0.50]{pictures/formicarium-use-case-diagram.png}
			\end{center}
			\legend{Fonte: os autores}
			% \caption{Fonte: própria}
		\end{figure}
	
	\subsection{Introdução}
	Faremos aqui uma descrição dos casos de uso não-triviais, importantes para entendimento da interação do usuário com o sistema. Como só temos um tipo de ator no sistema (Engenheiro do Nubank), o ator ao qual o caso de uso se refere fica implícito e não é mencionado na descrição dos casos de uso, e será mencionado simplificadamente apenas como "usuário".
	\subsection{Criar Devspace}
	   \begin{enumerate}
           \item Overview\newline
           Usuário cria um devspace.
           \item Descrição
           \begin{enumerate}
               \item Fluxo Básico
               \item Fluxos Alternativos
           \end{enumerate}
           \item Pré-condições
           \item Pós-condições
           \item Observações
       \end{enumerate}
		
    \section{Devspaces}
    
    Um Devspace, como foi batizado pelo grupo, é um ambiente de desenvolvimento isolado que roda em cima da plataforma Formicarium. Ele é o ambiente que o desenvolvedor vai ter disponível para uso e que vai interagir durante o seu tempo testando e desenvolvendo os serviços. 
    
    Os Devspaces são provisionados e configurados de forma automática pelo serviço Soil, a medida que um desenvolvedor requisita sua criação através da CLI. Para obter dados de configuração e setup inicial do Devspace, o Soil consulta um servidor de configurações via Webhooks, esse encarregado de fornecer todo configuração específica da empresa para fazer o bootstrap de um novo Devspace.
    
    Objetivamente, os Devspaces são Namespaces do Kubernetes que são gerenciados pelo Soil, além dos recursos padrões do Kubernetes, esse Namespaces acabam recebendo serviços adicionais do Formicarium, sendo esses o Hive e o Tanajura. A interação com os Devspaces é feito sempre através da CLI do Formicarium, não exigindo que o usuário tenha que ter o ferramental do Kubernetes instalado e configurado em sua máquina.
    
    Dentro de um Devspace os serviços que rodam nele conseguem se localizar entre si por meio do servidor de DNS do Kubernetes que garante isolamento entre Namespaces, dessa forma conseguimos alcançar um isolamento entre serviços entre Devspaces, mesmo que 2 desenvolvedores estejam executando o mesmo serviço. Além disso, cada Devspace recebe do Config Server um conjunto de aplicações de infra-estrutura ou de uso comum, que também garante isolamento dos demais Devspaces, como por exemplo, a existência de um broker de mensageria por Devspace. não havendo confusão na produção e consumo de mensagens.
    
        \begin{figure}[htbp]
			\caption{\label{fig_devspace1}Anatomia de um Devspace}
			\begin{center}
			\includegraphics[scale=0.30]{pictures/devspace1.png}
			\end{center}
			\legend{Fonte: os autores}
			% \caption{Fonte: própria}
		\end{figure}
    
    	\begin{figure}[htbp]
			\caption{\label{fig_create_devspace}Fluxo de Criação de Devspaces}
			\begin{center}
			\includegraphics[scale=0.40]{pictures/create-devspace.png}
			\end{center}
			\legend{Fonte: os autores}
			% \caption{Fonte: própria}
		\end{figure}

	\section{FileSync}

	Um dos grandes desafios do projeto foi a construção de um sistema para sincronização de arquivos em uma arquitetura distribuída de microsserviços.
	
	O caso de uso principal para esta funcionalidade é permitir que o engenheiro da Nubank pudesse iterar de maneira mais rápida no desenvolvimento de um novo microsserviço ou em modificações de algum existente.
	
	Do ponto de vista da empresa, esta era um dos requisitos mais desejados e que mais agregaria valor ao produto final, dado que é uma ferramenta extremamente poderosa para o engenheiro, garantindo-lhe mais produtividade e liberdade enquanto estivesse desenvolvendo.
	
	Este sistema de sincronização de arquivos precisava atender algumas premissas:
	- Deve se integrar facilmente ao workflow do engenheiro, para haver um incentivo à sua adoção.
	- Segurança: Os arquivos trafegados não devem ser, de maneira alguma, expostos para a internet ou suscetíveis a ataques como Man in the middle, dado que o conteúdo trafegado é extremamente sensível (códigos fonte dos produtos da empresa)
	- Velocidade: Quanto mais rápido for o processo de sincronização, mais dinâmico será o processo, permitindo iterações mais rápidas e, consequentemente, maior produtividade.

	Para entender o problema que o sistema de Filesync se propõe a resolver, é preciso entender o cenário:
	
	Os serviços em que o engenheiro está trabalhando não estão sendo compilados e executados na mesma máquina em que está o código fonte. Na verdade eles estão sendo executados em um contêiner Docker, gerenciado por um \textit{cluster} Kubernetes, operando em uma infraestrutura de \textit{hardware} fornecida pela AWS EC2. Para que mudanças no código fonte fossem de fato percebidas pelo desenvolvedor, este precisaria compilar uma nova imagem Docker com o código fonte atualizado, publica-lá em um repositório de contêineres e realizar a implantação desta nova imagem no \textit{cluster} remoto. Este processo, em um contexto de desenvolvimento, é extremamente ineficiente, o que tornaria a ferramenta pouco dinâmica e não atrativa para o engenheiro.

	Para evitar a geração de uma nova imagem Docker a cada iteração no código fonte, foi desenvolvida uma imagem genérica capaz de compilar e executar qualquer serviço da Nubank em modo de desenvolvimento. Esta imagem foi apelidada de Chamber e uma de suas características é a sua extensibilidade, permitindo que em melhorias futuras sejam desenvolvidas versões para outras linguagens e plataformas (Como por exemplo \textit{NodeJS}, \textit{Ruby}, \textit{Scala}, \textit{etc.}). Para implantação no Nubank, foi desenvolvida a imagem Chamber-lein, capaz de executar programas escritos em \textit{Clojure}, principal linguagem utilizada nos microsserviços do Nubank.
	
	Além disto, esta imagem tem um componente de software capaz de atualizar o código do serviço que está sendo executado dentro do contêiner através do Git.
	
% 	\section{Arquitetura da solução}
% 		\begin{figure}[htb]
% 			\caption{\label{fig_arquitetura1}Arquitetura da solução}
% 			\begin{center}
% 			\includegraphics[scale=0.50]{pictures/arquitetura-da-solucao.png}
% 			\end{center}
% 			\legend{Fonte: os autores}
% 		\end{figure}
	
	\subsection{Servidor web para Git (Tanajura)}
	Um dos componentes do sistema de sincronização de arquivos é um servidor web apelidado de \textit{Tanajura}. O serviço tem como principal responsabilidade ser um \textit{hub} de repositórios Git.
	
	Nestes repositórios está o código fonte dos serviços em que o desenvolvedor está trabalhando no momento e o Git é utilizado como mecanismo de sincronização entre o sistema de arquivos local da máquina do desenvolvedor e o sistema de arquivos do contêiner em que está sendo executado a aplicação, em um \textit{cluster} Kubernetes remoto.
	
	O serviço conta com \textit{endpoints} para gerenciamento de repositórios (operações de criação, remoção e consulta) através de uma interface REST, bem como um \textit{endpoint} que implementa os protocolos do Git para transferência e dados através de HTTP. Assim é possível para qualquer cliente Git a realização das operações básicas como \textit{push}, \textit{pull} e \textit{fetch}.
	
	Os repositórios Git neste serviço têm como característica a efemeridade, ou seja, eles não precisam ser de mecanismos robustos de persistência e só existem para fins de sincronização entre dois sistemas de arquivos, podendo ser sobrescritos e apagados a qualquer momento sem perda de dados importantes.
	
	A escolha do Git para este sistema de sincronização pode ser justificado por algumas de suas características que atendiam os requisitos definidos:
	
	- O binário do Git já está presente na máquina do desenvolvedor do Nubank, pois todos trabalham com Git em seu dia-a-dia.
	
	- É um método eficiente para troca de dados, pois os \textit{commits} são criados a partir das modificações feitas em arquivos, ou seja, apenas as diferenças são transmitidas pela rede.
	
	- A troca de dados pode ser criptografada com SSL.

	Ao receber um \textit{push} em algum repositório Git, o \textit{Tanajura} identifica qual o serviço associado ao repositório e faz uma requisição HTTP para o \textit{Soil} a fim de obter a URL do Gerenciador de Processo (\textit{Stinger}) deste serviço.
	
	Uma vez obtida esta URL, o serviço \textit{Tanajura} faz uma requisição para o \textit{Stinger} avisando-o de que há uma nova versão do código disponível para ser sincronizada.
	
	Este, por sua vez, realiza um \textit{pull} no repositório remoto para obtenção do código atualizado e, após o recebimento dos arquivos, executa os \textit{scripts} necessários para recompilação e execução do código.
	
	Esta parte do processo pode ser representada pelo seguinte diagrama de sequência:
		\begin{figure}[htb]
			\caption{\label{fig_arquitetura2}Fluxo do Tanajura}
			\begin{center}
			\includegraphics[scale=0.29]{pictures/tanajura-flow.png}
			\end{center}
			\legend{Fonte: os autores}
			% \caption{Fonte: própria}
		\end{figure}

	Em termos práticos, o processo ocorre da seguinte maneira:
	
	Quando o desenvolvedor deseja implantar em seu devspace um serviço com capacidades de sincronização, ele digita o seguinte o comando:

	\begin{verbatim}
	fmc service:deploy:local my-service -f ./config.json /path/to/service
	\end{verbatim}

	Este comando irá realizar a implantação de um serviço chamado \textit{"my-service"}, utilizando o arquivo de configuração \textit{"./config.json"} a partir da pasta local \textit{"/path/to/service"}

	\subsection{Gerenciador de Processos (Stinger)}	
	
	Para que fosse possível o método de sincronização de arquivos utilizando Git foi necessário o desenvolvimento de uma aplicação que, através de uma interface HTTP exposta para o \textit{cluster}, pudesse fazer \textit{pull} em um repositório Git remoto para obtenção do código fonte atualizado e, após o recebimento dos arquivos, fosse possível executar um comando arbitrário para que o processo do serviço pudesse ser recarregado.
	
	Esta aplicação foi apelidada de Stinger e é o binário executado primariamente pela imagem Docker onde os serviços são executados (esta imagem será descrita em detalhes mais adiante). Os endpoints HTTP disponíveis neste serviço são:

    \textbf{POST /reset}
	\newline
	Ao receber uma requisição neste endpoint, o Stinger termina o processo do serviço em execução através de seu identificador de processo (\textit{process ID}) e executa o \textit{script} de \textit{cleanup}. Após a garantia de que o processo do serviço foi terminado com êxito, é executado o \textit{script} de \textit{start}, que garante sua reinicialização.
	
	\textbf{POST /pull}
	\newline
	Ao receber uma requisição neste endpoint, o Stinger executa o comando git pull origin master para obter a versão mais recente do código no repositório remoto. É possível, através de parâmetros no corpo da requisição, fazer com que o processo do serviço seja reinicializado logo após o recebimento do código atualizado.

	Quando o Stinger é iniciado, ele verifica a existência do repositório Git local e, caso não o encontre, executa o comando \textit{git clone [url do repositório] [pasta local]} para obter a versão inicial do código. Logo após o recebimento dos arquivos, é feito o processo de inicialização do serviço.

	É possível configurar diversos parâmetros de funcionamento do \textit{Stinger} através de variáveis de ambiente. Os mais relevantes são:
	
	\textbf{APP\_PATH}
	\newline
	É a o caminho para o diretório local onde o Stinger irá clonar o código do repositório remoto.
	
	\textit{exemplo: /app}

	\textbf{STINGER\_SCRIPTS}
	\newline
	Caminho para o diretório local onde o Stinger irá executar os scripts para gerenciar os ciclos de vida do serviço. Dentro desta pasta, devem estar presentes os scripts de start e cleanup.
	
	\textit{exemplo: /scripts}
	
	\textbf{GIT\_URL}
	\newline
	É a URL de onde o \textit{Stinger} fará o \textit{git clone} inicial dos arquivos.
	
	\textit{exemplo: \url{https://tanajura.joe.formicarium.nubank.com.br/service-name}}
	
	\textbf{START\_AFTER\_PULL}
	\newline
	Caso esta variável esteja setada, o \textit{Stinger} irá reinicializar o processo sempre após o recebimento de novo código através do \textit{pull}. Esta configuração existe porque em certas linguagens de programação (como a utilizada pela Nubank) não é necessário recompilar e nem executar nenhum comando para que o novo código obtido seja aplicado no processo em execução.
    
	De maneira geral, o \textit{Stinger} é um gerenciador de processos integrado com o Git e que expõe suas funcionalidades através de um servidor HTTP.

\section{Frontend}
    \subsection{Organização do código}
Para oferecer uma interface amigável aos usuários, foram construídas duas aplicações: uma Interface de linha de comando e uma Aplicação \textit{Desktop}. Ambas têm funcionalidades semelhantes, porém a segunda oferece elementos de interface gráfica essenciais para a construção do módulo de \textit{Distributed Debugger} do sistema.

Como as duas aplicações compartilham diversos módulos, todo o código comum foi extraído para uma biblioteca (chamada \textit{common}) e seu código fica disponível para ambas as aplicações através de um sistema de dependências oferecido pelo NPM.

Foi tomado o cuidado de não se criar acoplamentos dos módulos desta biblioteca com casos de uso específicos de cada aplicação, tornando o código mais reaproveitável e desacoplado, com responsabilidades bem definidas.

O código dos três módulos vive em mesmo repositório Git, dividido apenas por pastas. Esta prática é comum para o gerenciamento de múltiplos módulos que compõe um sistema maior e  repositórios com esta característica são denominados \textit{monorepos}.

Este tipo de organização é vantajosa pois preserva os benefícios de desacoplamento das diferentes partes do sistema, porém eliminando, através do uso de ferramentas específicas, as complexidades de se gerenciar as dependências entre os diversos módulos, tanto no estágio de desenvolvimento quanto nos estágios de compilação e publicação.

Para gerenciar as dependências do \textit{monorepo}, foi utilizado a ferramenta \textit{yarn workspaces}, que otimiza o uso de memória em disco do código fonte e o tempo de instalação inicial para novos desenvolvedores através do compartilhamento das dependências comuns entre os vários módulos. Ela também é responsável por criar \textit{links} simbólicos (\textit{symlinks}) entre os módulos quando em estágio de desenvolvimento. Os \textit{symlinks} permitem iterações mais rápidas de desenvolvimento, pois uma mudança no código de uma dependência irá refletir automaticamente nos módulos dependentes, sem a necessidade de se incrementar versões e recompilar partes do programa.

Todos os módulos do projeto utilizam \textit{Semantic Versioning} como padrão versionamento. O incremento é feito automaticamente através de uma ferramenta que analisa as mensagens presentes nos commits do Git para determinar, através de \textit{tokens} pré-definidos, qual será o incremento de versão: \textit{Major}, \textit{minor}, \textit{patch}.

Além do incremento automático em cada módulo, foi utilizada a ferramenta \textit{Lerna} para determinar quais módulos e dependências devem ter suas versões atualizadas, através também da análise de quais arquivos foram modificados nos commits desde a última atualização.

Todo este ferramental tornou a experiência de desenvolvimento deste projeto muito mais eficiente e facilitará também sua manutenção.

    \subsection{Interface de linha de comando}
    Para a construção deste software, foi utilizado a linguagem Typescript, com a plataforma NodeJS. A framework para desenvolvimento foi a ocli, mantida pela Salesforce.
    Este software é distribuído através do NPM (\textit{Node Package Manager)}. Por ser uma ferramenta já presente nos computadores dos engenheiros do Nubank, a instalação da linha de comando se torna simples e rápida, basta executar o comando
    \begin{verbatim}
	npm install -g @formicarium/cli
	\end{verbatim}
	
	Com isso, o binário \textit{fmc} já fica disponível para ser executado através do terminal.
	
	Para atualizar a versão do software após a publicação de alguma modificação, basta o comando
	\begin{verbatim}
	npm update -g @formicarium/cli
	\end{verbatim}
	
	Este mecanismo de fácil distribuição e atualização foi escolhido para facilitar ainda mais a adesão dos engenheiros ao uso do ecossistema Formicarium.

A interface de linha de comando apresenta suas funcionalidades divididas em subprogramas, cada um referente a um conjunto de casos de uso agrupados logicamente. Utilizando o comando \textit{help}, o engenheiro tem acesso à documentação da ferramenta, podendo listar os subprogramas e comandos disponíveis dentro de cada nível hierárquico de funcionalidades e entender o que fazem através de descrições e exemplos de uso.

Por exemplo, ao requisitar ajuda no contexto geral da linha de comando:

\begin{verbatim}
A CLI to operate on Formicarium
VERSION
    @formicarium/cli/1.3.2 darwin-x64 node-v11.1.0
USAGE
    $ fmc [COMMAND]
COMMANDS
    devspace  Creates a Devspace
    git       Configures local fmcgit and hive
    help      display help for fmc
    repl      Connects to remote repl. If no service is provided, connects on Hive's Repl
    service   Deletes a service in the current Devspace
    setup     Configures Formicarium CLI to one cluster
\end{verbatim}

Ao requisitar ajuda para um contexto específico (no caso, o contexto \textit{devspace}):
\begin{verbatim}
Creates a Devspace

USAGE
  $ fmc devspace:COMMAND

COMMANDS
  devspace:create    Creates a Devspace
  devspace:delete    Deletes a Devspace
  devspace:info      Get information for the current devspace
  devspace:list      List availables Devspaces
  devspace:services  Lists the services in your devspace
  devspace:use       Configures to use one Devspace context
\end{verbatim}


Ao requisitar ajuda para um comando específico (no caso, o comando \textit{devspace:create}):
\begin{verbatim}
Creates a Devspace

USAGE
  $ fmc devspace:create ID

OPTIONS
  -h, --help  show CLI help
  --test

EXAMPLE
  $ fmc devspace:create paps
\end{verbatim}


A facilidade proporcionada ao engenheiro do Nubank para entender o uso da ferramenta através desta documentação interativa fez parte da estratégia do grupo para disseminação e adesão da ferramenta por toda a empresa de maneira escalável.

Lista de comandos disponíveis e uma breve descrição do que fazem

devspace
  devspace:create    Creates a Devspace
  devspace:delete    Deletes a Devspace
  devspace:info      Get information for the current devspace
  devspace:list      List availables Devspaces
  devspace:services  Lists the services in your devspace
  devspace:use       Configures to use one Devspace context
  

sync
  sync:push   Configures local fmcgit and hive
  sync:setup  Deploys service

repl

service
  service:delete   Deletes a service in the current Devspace
  service:deploy   Deploys service
  service:logs     A service logs in the current Devspace
  service:restart  Restart a service deployed in dev mode
  service:status   Restart a service deployed in dev mode
  

setup




    \subsection{Aplicação \textit{Desktop}}

Como parte do ferramental do ambiente Formicarium, foi desenvolvida uma aplicação Desktop multiplataforma (Windows, Linux, OS X) com o intuito de melhorar a experiência dos usuários nas funções mais comuns e também para atender requisitos do sistema que exigiam interfaces gráficas mais interativas e avançadas. A aplicação foi desenvolvida utilizando tecnologias web (HTML5, CSS3 e Javascript), o que tornou possível sua execução em diferentes plataformas utilizadas pelos engenheiros do Nubank. Como era necessário o uso de \textit{APIs} nativas do sistema (como acesso ao sistema de arquivos e execução de outros programas a partir da interface gráfica) que não seriam possível no browser, foi utilizada a \textit{framework} Electron para empacotar a aplicação em um binário capaz de ter acesso às \textit{system calls} necessárias. Electron é a framework por trás de diversos projetos populares como Slack, WhatsApp Desktop, Visual Studio Code, Atom, Spotify entre outros. Além disso, conta com uma enorme comunidade, melhorando ainda as características de manutenibilidade de software da solução.

Para a sua distribuição dentro do Nubank, o software compilado foi disponibilizado em um \textit{bucket} da \textit{AWS S3} acessível apenas para funcionários credenciados \textit{download} e execução para começar a utilizá-lo.

A aplicação ainda não conta com sistemas automatizados de atualização, sendo necessária a obtenção manual de uma nova versão sempre que o engenheiro veja a necessidade de atualização. Este mecanismo de atualização poderá ser aprimorado em melhoria futuras.

\subsection{Gerenciamento de Devspaces}
Esta área tem como objetivo mostrar ao engenheiro os Devspaces disponíveis para serem utilizados. Normalmente o Devspace pessoal do engenheiro estará selecionado, porém é possível por exemplo alternar entre este e o Devspace do \textit{squad} ou ainda o de algum colega caso queiram compartilhar alguma configuração para reproduzir ambientes de testes e desenvolvimento.

\begin{figure}[htb]
	\caption{\label{fig_frontend_devspaces}Tela Lista de Devspaces}
	\begin{center}
	\includegraphics[width=\textwidth,keepaspectratio]{pictures/frontend/frontend-devspaces.png}
	\end{center}
	\legend{Fonte: Elaborado pelos autores}
\end{figure}



\subsection{Devspace}
Esta área tem como objetivo mostrar informações e proporcionar interações com o Devspace específico selecionado pelo engenheiro.

\subsubsection{Infraestrutura}
Nesta área o engenheiro pode conferir o status dos serviços básicos de infraestrutura do Devspace, como o Hive (para \textit{Distributed Tracing}) e o Tanajura (para sincronização de arquivos). Também é possível extrair os logs destes serviços em tempo real.

\begin{figure}[htb]
	\caption{\label{fig_frontend_devspace_info}Tela Informações do Devspace}
	\begin{center}
	\includegraphics[width=\textwidth,keepaspectratio]{pictures/frontend/frontend-devspace-info.png}
	\end{center}
	\legend{Fonte: Elaborado pelos autores}
\end{figure}

\subsubsection{Serviços}

Nesta área o engenheiro pode conferir o status dos serviços implantados no Devspace atual e também interagir com cada um deles de forma independente. É possível a obtenção em tempo real dos \textit{logs} (tudo que for direcionado ao \textit{stdout} e \textit{stderr} do processo), a reinicialização do processo e também a sua remoção do Devspace através de botões. A lista também apresenta as interfaces de cada processo expostas para a \textit{internet} para permitir outros tipos de interação, como por exemplo a interface de um possível servidor HTTP do serviço e a interface HTTP do Stinger, que é um gerenciador de processos oferecido pelo Formicarium e que está presente nos serviços implantados no Devspace.

\begin{figure}[htb]
	\caption{\label{fig_frontend_devspace_services}Tela Serviços do Devspace}
	\begin{center}
	\includegraphics[width=\textwidth,keepaspectratio]{pictures/frontend/frontend-devspace-services.png}
	\end{center}
	\legend{Fonte: os autores - 2018-11-10}
\end{figure}

\begin{figure}[htb]
	\caption{\label{fig_frontend_logs}Tela Logs de um serviço}
	\begin{center}
	\includegraphics[width=\textwidth,keepaspectratio]{pictures/frontend/frontend-logs.png}
	\end{center}
	\legend{Fonte: Elaborado pelos autores}
\end{figure}

\subsubsection{Deploy}

Esta área conta com um formulário para implantação de um novo serviço. É possível inserir o nome, escolher se o serviço é do tipo \textit{Syncable} (o que fará com que a imagem Docker \textit{Chamber} seja usada). Caso esta opção esteja selecionada, o engenheiro deve apontar o diretório local em que está o código fonte do serviço para que este seja enviado para o contêiner remota e possa ser sincronizado em seguida.

\begin{figure}[htb]
	\caption{\label{fig_frontnd_deploy}Tela Deploy de serviços}
	\begin{center}
	\includegraphics[width=\textwidth,keepaspectratio]{pictures/frontend/frontend-deploy.png}
	\end{center}
	\legend{Fonte: Elaborado pelos autores}
\end{figure}

\subsubsection{Distributed Debugger}

\subsubsection{Sync}

\subsubsection{Configurações}

\begin{figure}[htb]
		\caption{\label{fig_frontend_sync}Tela Sincronização de arquivos em um serviço}
		\begin{center}
		\includegraphics[width=\textwidth,keepaspectratio]{pictures/frontend/frontend-sync.png}
		\end{center}
		\legend{Fonte: Elaborado pelos autores}
	\end{figure}
	
\begin{figure}[htb]
		\caption{\label{fig_frontend_tracing_details}Tela Detalhes de uma requisição}
		\begin{center}
		\includegraphics[width=\textwidth,keepaspectratio]{pictures/frontend/frontend-tracing-details.png}
		\end{center}
		\legend{Fonte: Elaborado pelos autores}
	\end{figure}
	
\begin{figure}[htb]
		\caption{\label{fig_frontend_tracing}Tela Grafo de interações em Tracing}
		\begin{center}
		\includegraphics[width=\textwidth,keepaspectratio]{pictures/frontend/frontend-tracing.png}
		\end{center}
		\legend{Fonte: Elaborado pelos autores}
	\end{figure}

\begin{figure}[htb]
		\caption{\label{fig_frontend_create_devspace}Tela Criar novo Devspace}
		\begin{center}
		\includegraphics[width=\textwidth,keepaspectratio]{pictures/frontend/frontend-create-devspace.png}
		\end{center}
		\legend{Fonte: Elaborado pelos autores}
	\end{figure}

\chapter{Testes e Avaliação}
\chapter{Considerações Finais}
	\section{Conclusões do Projeto de Formatura}
	\section{Contribuições}
	\section{Perspectivas de Continuidade}
	

%\capepigrafe[0.5\textwidth]{``Frase espirituosa de um autor famoso''}{Autor famoso}

%\begin{citacaoLonga}
%	\blindtext
%\end{citacaoLonga}

%\blinddocument


% ========== Referências ==========
% --- IEEE ---
%	http://www.ctan.org/tex-archive/macros/latex/contrib/IEEEtran
%\bibliographystyle{IEEEbib}

% --- ABNT (requer ABNTeX 2) ---
%	http://www.ctan.org/tex-archive/macros/latex/contrib/abntex2
\bibliographystyle{abntex2-num}

\bibliography{referencias}


% ========== Apêndices (opcional) ==========
%\apendice
%\chapter{}
%\chapter{Beta}


% ========== Anexos (opcional) ==========
%\anexo
%\chapter{Alpha}
%\chapter{}



\end{document}
